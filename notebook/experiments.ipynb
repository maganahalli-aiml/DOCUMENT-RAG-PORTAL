{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f567ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all_ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f86d93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc02c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09de472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79986030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, so I need to figure out what the capital of Germany is. Hmm, I\\'m not entirely sure, but I think it\\'s a city I\\'ve heard before. Let me try to remember. I know that Germany is a country in Europe, and it\\'s pretty well-known. I\\'ve heard of cities like Berlin, Munich, Hamburg, and Frankfurt. \\n\\nWait, I think Berlin is the capital. But I\\'m not 100% certain. I remember learning something about it in school, but it\\'s been a while. Maybe I can think of other clues. For example, I know that the Berlin Wall was a significant historical landmark, and that was in Berlin. Also, I think the German parliament is there. \\n\\nBut just to make sure, I should consider the other options. Munich is in the south, known for Oktoberfest. Hamburg is a major port city in the north. Frankfurt is a financial hub. None of those sound like capitals, but I could be wrong. \\n\\nAnother way to think about it: when I hear \"capital of Germany,\" the first city that comes to mind is Berlin. I also recall that before reunification, West Germany\\'s capital was Bonn, and after reunification, it moved to Berlin. So that makes sense. \\n\\nI don\\'t think I\\'ve heard anyone refer to Munich or Hamburg as the capital. Frankfurt is more about banking. So putting it all together, I\\'m pretty confident the capital of Germany is Berlin.\\n</think>\\n\\nThe capital of Germany is Berlin.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 311, 'prompt_tokens': 10, 'total_tokens': 321, 'completion_time': 1.447415098, 'prompt_time': 0.000626699, 'queue_time': 0.201893866, 'total_time': 1.4480417970000001}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--1b1d8125-1af5-482b-9877-6f18dc5b6bdd-0' usage_metadata={'input_tokens': 10, 'output_tokens': 311, 'total_tokens': 321}\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your-model-name' with the actual model name string, e.g., \"qwen2\"\n",
    "# ChatGroq is already imported in cell 2\n",
    "model=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")\n",
    "response = model.invoke(\"What is the capital of Germany?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209eaad",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53d1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc38d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: AIzaSyDDNT_V2jb5vBzTWiRyJoinHsZP_VkejuI\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "print('GOOGLE_API_KEY:', os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "692a9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f056468",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d45e08bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022623702883720398,\n",
       " -0.03944942727684975,\n",
       " -0.033464282751083374,\n",
       " -0.008350953459739685,\n",
       " 0.04586751013994217,\n",
       " 0.007354647386819124,\n",
       " -0.009275938384234905,\n",
       " -0.021549616008996964,\n",
       " 0.014098637737333775,\n",
       " 0.0726904347538948,\n",
       " -0.011754732578992844,\n",
       " -0.0032495397608727217,\n",
       " -0.0017697095172479749,\n",
       " 0.018062682822346687,\n",
       " 0.0077929263934493065,\n",
       " -0.010148140601813793,\n",
       " -0.0024199795443564653,\n",
       " 0.055163703858852386,\n",
       " 0.033233918249607086,\n",
       " -0.018589084967970848,\n",
       " -0.003447713563218713,\n",
       " 0.009337568655610085,\n",
       " -0.021200010553002357,\n",
       " 0.013261038810014725,\n",
       " 0.0328763872385025,\n",
       " -0.038254767656326294,\n",
       " -0.017260802909731865,\n",
       " -0.05388926714658737,\n",
       " -0.0001561641984153539,\n",
       " -0.006300874520093203,\n",
       " -0.06571874767541885,\n",
       " 0.01848682574927807,\n",
       " 0.008000959642231464,\n",
       " 0.0005863052792847157,\n",
       " 0.011942715384066105,\n",
       " -0.04978764429688454,\n",
       " -0.01106940396130085,\n",
       " -0.00769378524273634,\n",
       " -0.031237248331308365,\n",
       " 0.0662180706858635,\n",
       " -0.015391629189252853,\n",
       " -0.033699966967105865,\n",
       " -0.06846331059932709,\n",
       " 0.00871167704463005,\n",
       " -0.013922431506216526,\n",
       " -0.01675533875823021,\n",
       " -0.02674809657037258,\n",
       " 0.03701697289943695,\n",
       " 0.050077494233846664,\n",
       " -0.03265852481126785,\n",
       " 0.007336609531193972,\n",
       " -0.00786242913454771,\n",
       " 0.050264522433280945,\n",
       " 0.008199149742722511,\n",
       " -0.00016084361413959414,\n",
       " -0.07044949382543564,\n",
       " 0.0006461241864599288,\n",
       " -0.029279861599206924,\n",
       " 0.02693082205951214,\n",
       " 0.02958701364696026,\n",
       " 0.02804272621870041,\n",
       " -0.03392765671014786,\n",
       " -0.011155865155160427,\n",
       " 0.05555254593491554,\n",
       " 0.0013458917383104563,\n",
       " -0.060896649956703186,\n",
       " 0.0081617571413517,\n",
       " 0.02676011435687542,\n",
       " 0.08380851149559021,\n",
       " -0.012666180729866028,\n",
       " -0.006581773981451988,\n",
       " -0.04246075078845024,\n",
       " 0.05339723452925682,\n",
       " -0.009551752358675003,\n",
       " 0.015801632776856422,\n",
       " -0.06754837185144424,\n",
       " -0.024353522807359695,\n",
       " 0.06266111880540848,\n",
       " -0.0017527247546240687,\n",
       " -0.03288768231868744,\n",
       " 0.013586295768618584,\n",
       " -0.045762866735458374,\n",
       " -0.0721883550286293,\n",
       " -0.018645260483026505,\n",
       " -0.05025337263941765,\n",
       " 0.020329397171735764,\n",
       " -0.04539837688207626,\n",
       " -0.0030723465606570244,\n",
       " -0.03926093131303787,\n",
       " 0.054580867290496826,\n",
       " -0.0243698600679636,\n",
       " -0.0025565619580447674,\n",
       " 0.06319983303546906,\n",
       " -0.04627343267202377,\n",
       " -0.022236229851841927,\n",
       " 0.09225299209356308,\n",
       " -0.009239459410309792,\n",
       " -0.024139782413840294,\n",
       " 0.059111908078193665,\n",
       " -0.015674646943807602,\n",
       " 0.019629990682005882,\n",
       " -0.053834669291973114,\n",
       " -0.08000358194112778,\n",
       " 0.04854133352637291,\n",
       " 0.04109853506088257,\n",
       " 0.03380345180630684,\n",
       " 0.001076209475286305,\n",
       " 0.028221607208251953,\n",
       " -0.005482272244989872,\n",
       " 0.04544379562139511,\n",
       " -0.05489847809076309,\n",
       " -0.027414552867412567,\n",
       " 0.06029582768678665,\n",
       " 0.041785672307014465,\n",
       " 0.010611494071781635,\n",
       " -0.05479324236512184,\n",
       " -0.028009597212076187,\n",
       " -0.01355162262916565,\n",
       " 0.027701761573553085,\n",
       " 0.014453673735260963,\n",
       " 0.030607035383582115,\n",
       " -0.005794708617031574,\n",
       " 0.038636960089206696,\n",
       " -0.06499813497066498,\n",
       " 0.023212088271975517,\n",
       " -0.0219572726637125,\n",
       " -0.04781733453273773,\n",
       " 0.026848796755075455,\n",
       " -0.039795733988285065,\n",
       " 0.03699267655611038,\n",
       " 0.03550741448998451,\n",
       " -0.04297490045428276,\n",
       " -0.026278069242835045,\n",
       " 0.024616839364171028,\n",
       " -0.009358084760606289,\n",
       " 0.04808348789811134,\n",
       " 0.03588598966598511,\n",
       " -0.035219259560108185,\n",
       " 0.0230910312384367,\n",
       " -0.0008131192298606038,\n",
       " 0.025250982493162155,\n",
       " 0.0649355873465538,\n",
       " 0.01030638162046671,\n",
       " 0.048951778560876846,\n",
       " 0.0068491664715111256,\n",
       " 0.05899510160088539,\n",
       " -0.03937271982431412,\n",
       " -0.03660793602466583,\n",
       " 0.05115404725074768,\n",
       " -0.0622483566403389,\n",
       " -0.06611651182174683,\n",
       " -0.02731466107070446,\n",
       " -0.03561079874634743,\n",
       " -0.03185088932514191,\n",
       " 0.056373730301856995,\n",
       " 0.028180867433547974,\n",
       " -0.029688866809010506,\n",
       " 0.043807607144117355,\n",
       " 0.039681337773799896,\n",
       " -0.011776717379689217,\n",
       " 0.03254152089357376,\n",
       " 0.021073326468467712,\n",
       " 0.0053675188682973385,\n",
       " 0.005838979966938496,\n",
       " -0.01453948300331831,\n",
       " -0.02399769425392151,\n",
       " 0.007037383038550615,\n",
       " -0.00481147738173604,\n",
       " 0.01497767772525549,\n",
       " -0.00460796058177948,\n",
       " -0.030675871297717094,\n",
       " -0.003418450243771076,\n",
       " 0.001173631870187819,\n",
       " -0.03448234125971794,\n",
       " 0.01806236431002617,\n",
       " -0.043974850326776505,\n",
       " 0.00960663240402937,\n",
       " -0.0016134805046021938,\n",
       " -0.03744547441601753,\n",
       " -0.004427469335496426,\n",
       " 0.014645222574472427,\n",
       " -0.05014475807547569,\n",
       " -0.006895797792822123,\n",
       " 0.0400250144302845,\n",
       " -0.009502899833023548,\n",
       " -0.017106279730796814,\n",
       " 0.04362279921770096,\n",
       " -0.005801925901323557,\n",
       " -0.0018511604284867644,\n",
       " 0.023125842213630676,\n",
       " -0.045798882842063904,\n",
       " 0.004167983774095774,\n",
       " -0.018016451969742775,\n",
       " -0.023866549134254456,\n",
       " -0.05450146645307541,\n",
       " -0.022184625267982483,\n",
       " 0.01806580275297165,\n",
       " -0.028407776728272438,\n",
       " 0.02864718995988369,\n",
       " -0.06305550783872604,\n",
       " -0.046719424426555634,\n",
       " 0.047272469848394394,\n",
       " 0.015223459340631962,\n",
       " -0.02253131940960884,\n",
       " 0.022399891167879105,\n",
       " 0.003477050457149744,\n",
       " 0.08750580251216888,\n",
       " -0.030538320541381836,\n",
       " -0.007393908221274614,\n",
       " 0.027281884104013443,\n",
       " -0.02380552515387535,\n",
       " 0.010597293265163898,\n",
       " 0.0033513500820845366,\n",
       " -0.004453897010535002,\n",
       " 0.04838103801012039,\n",
       " -0.03324652835726738,\n",
       " 0.07534162700176239,\n",
       " -0.0009334567585028708,\n",
       " 0.03385906666517258,\n",
       " -0.010659858584403992,\n",
       " -0.04309844970703125,\n",
       " 0.022323358803987503,\n",
       " -0.028896750882267952,\n",
       " -0.028536584228277206,\n",
       " 0.000573913159314543,\n",
       " 0.02335706166923046,\n",
       " -0.017209883779287338,\n",
       " -0.02853008545935154,\n",
       " 0.0061187888495624065,\n",
       " -0.02617589198052883,\n",
       " -0.031954534351825714,\n",
       " 0.06866902112960815,\n",
       " 0.034593142569065094,\n",
       " -0.0033351541496813297,\n",
       " 0.04762555658817291,\n",
       " 0.03701965883374214,\n",
       " -0.006789534352719784,\n",
       " 0.01824811100959778,\n",
       " -0.0049891360104084015,\n",
       " -0.003185770008713007,\n",
       " -0.03660878166556358,\n",
       " -0.029070546850562096,\n",
       " 0.04721760377287865,\n",
       " 0.031222956255078316,\n",
       " -0.045782048255205154,\n",
       " -0.050822898745536804,\n",
       " -0.02125730738043785,\n",
       " 0.04941154271364212,\n",
       " 0.043514564633369446,\n",
       " 0.07234945893287659,\n",
       " 0.01580132357776165,\n",
       " 0.006966623477637768,\n",
       " 0.015536444261670113,\n",
       " 0.0343448705971241,\n",
       " -0.04509450122714043,\n",
       " 0.0022321124561131,\n",
       " -0.04857398569583893,\n",
       " 0.029116520658135414,\n",
       " -0.026241961866617203,\n",
       " 0.026162518188357353,\n",
       " 0.024109425023198128,\n",
       " 0.04314068704843521,\n",
       " 0.05259094014763832,\n",
       " -0.03950868919491768,\n",
       " 1.574732414155733e-05,\n",
       " -0.027491740882396698,\n",
       " 0.010350419208407402,\n",
       " -0.047519128769636154,\n",
       " 0.008934838697314262,\n",
       " -0.00957739818841219,\n",
       " -0.0009828406618908048,\n",
       " -0.09865092486143112,\n",
       " 0.01052707526832819,\n",
       " 0.042720094323158264,\n",
       " 0.017737694084644318,\n",
       " 0.004191206768155098,\n",
       " -0.03492308035492897,\n",
       " 0.05559380352497101,\n",
       " 0.04563174769282341,\n",
       " -0.06100599840283394,\n",
       " 0.04412595555186272,\n",
       " 0.046807367354631424,\n",
       " -0.003706200746819377,\n",
       " -0.020675158128142357,\n",
       " -0.0037899762392044067,\n",
       " -0.015288915485143661,\n",
       " -0.049969106912612915,\n",
       " -0.010200591757893562,\n",
       " -0.017176060006022453,\n",
       " -0.04590925946831703,\n",
       " -0.043852269649505615,\n",
       " -0.06960059702396393,\n",
       " -0.0013789322692900896,\n",
       " -0.042754579335451126,\n",
       " -0.08832480013370514,\n",
       " -0.016253871843218803,\n",
       " -0.03580518066883087,\n",
       " 0.03840746358036995,\n",
       " 0.04004482179880142,\n",
       " -0.014663304202258587,\n",
       " -0.052344974130392075,\n",
       " -0.023387817665934563,\n",
       " 0.032759200781583786,\n",
       " -0.0719192773103714,\n",
       " 0.009212645702064037,\n",
       " 0.01679094322025776,\n",
       " -0.05043598636984825,\n",
       " -0.07248566299676895,\n",
       " 0.04326877370476723,\n",
       " 0.050523851066827774,\n",
       " 0.025932101532816887,\n",
       " -0.023574866354465485,\n",
       " -0.060479190200567245,\n",
       " -0.00787085946649313,\n",
       " -0.02185492403805256,\n",
       " 0.05075828731060028,\n",
       " -0.04477005824446678,\n",
       " -0.0015944114420562983,\n",
       " -0.008636390790343285,\n",
       " 0.04501147195696831,\n",
       " 0.003937301691621542,\n",
       " 0.08959347009658813,\n",
       " 0.018531499430537224,\n",
       " -0.04397108405828476,\n",
       " -0.003804014530032873,\n",
       " 0.04702106863260269,\n",
       " 0.0017974402289837599,\n",
       " 0.03580252081155777,\n",
       " 0.005202157888561487,\n",
       " 0.005281470250338316,\n",
       " -0.014108153991401196,\n",
       " 0.029704073444008827,\n",
       " -0.05281628668308258,\n",
       " 0.024297714233398438,\n",
       " 0.019144665449857712,\n",
       " 0.0468047671020031,\n",
       " -0.04584713652729988,\n",
       " 0.030952969565987587,\n",
       " -0.06432204693555832,\n",
       " 0.01575534977018833,\n",
       " 0.07246699929237366,\n",
       " 0.04589470475912094,\n",
       " -0.01339185331016779,\n",
       " -0.04960155487060547,\n",
       " -0.0007960167131386697,\n",
       " -0.0007198594394139946,\n",
       " -0.03549576178193092,\n",
       " 0.02106769010424614,\n",
       " 0.07837969809770584,\n",
       " 0.024930689483880997,\n",
       " 0.01462351530790329,\n",
       " 0.1019689291715622,\n",
       " 0.004772263579070568,\n",
       " 0.04302672669291496,\n",
       " -0.004887877497822046,\n",
       " -0.03910781070590019,\n",
       " 0.05130992457270622,\n",
       " -0.014239841140806675,\n",
       " 0.02865137718617916,\n",
       " -0.05623089522123337,\n",
       " -0.011449985206127167,\n",
       " 0.0007267282926477492,\n",
       " -0.023523151874542236,\n",
       " -0.04887892305850983,\n",
       " -0.020935572683811188,\n",
       " -0.03666966035962105,\n",
       " -0.026277810335159302,\n",
       " 0.011076478287577629,\n",
       " 0.020581649616360664,\n",
       " 0.010341480374336243,\n",
       " 0.04223106801509857,\n",
       " 0.03326969966292381,\n",
       " 0.02774103172123432,\n",
       " -0.03423522412776947,\n",
       " 0.045224398374557495,\n",
       " 0.027766002342104912,\n",
       " -0.06972961127758026,\n",
       " -0.00701026851311326,\n",
       " -0.009249210357666016,\n",
       " 0.0146812554448843,\n",
       " -0.03210248425602913,\n",
       " -0.0005518338293768466,\n",
       " 0.060655027627944946,\n",
       " 0.01881048083305359,\n",
       " 0.021924937143921852,\n",
       " -0.02672482281923294,\n",
       " 0.008216881193220615,\n",
       " 0.038808103650808334,\n",
       " 0.004576296079903841,\n",
       " 0.0590389147400856,\n",
       " -0.056837547570466995,\n",
       " 0.0622708797454834,\n",
       " 0.06713372468948364,\n",
       " -0.016589166596531868,\n",
       " -0.0047628069296479225,\n",
       " -0.03155810758471489,\n",
       " 0.0016824282938614488,\n",
       " -0.01164279319345951,\n",
       " 0.024249453097581863,\n",
       " 0.010761485435068607,\n",
       " -0.0027493946254253387,\n",
       " -0.0621565617620945,\n",
       " 0.007851588539779186,\n",
       " -0.016088606789708138,\n",
       " -0.037716031074523926,\n",
       " -0.0037327646277844906,\n",
       " -0.00579106155782938,\n",
       " -0.004230659455060959,\n",
       " -0.02910826914012432,\n",
       " 0.024258818477392197,\n",
       " 0.004797599744051695,\n",
       " -0.02965429797768593,\n",
       " 0.011512698605656624,\n",
       " -0.04485514387488365,\n",
       " -0.04820375517010689,\n",
       " -0.011212009936571121,\n",
       " 0.015357768163084984,\n",
       " -0.031150583177804947,\n",
       " 0.008654344826936722,\n",
       " 0.08563004434108734,\n",
       " -0.02112104743719101,\n",
       " -0.003708244999870658,\n",
       " 0.011304833926260471,\n",
       " -4.16973780374974e-05,\n",
       " -0.0680646151304245,\n",
       " -0.06045186519622803,\n",
       " 0.00023891765158623457,\n",
       " 0.030258281156420708,\n",
       " 0.03427932411432266,\n",
       " -0.011535318568348885,\n",
       " 0.026504578068852425,\n",
       " 0.010206688195466995,\n",
       " -0.0606096014380455,\n",
       " -0.05306370183825493,\n",
       " -0.03780308738350868,\n",
       " -0.05755196139216423,\n",
       " 0.008400078862905502,\n",
       " 0.027211591601371765,\n",
       " -0.010938749648630619,\n",
       " 0.034941039979457855,\n",
       " -0.006829920690506697,\n",
       " -0.010489080101251602,\n",
       " 0.041605133563280106,\n",
       " 0.032529573887586594,\n",
       " -0.030690068379044533,\n",
       " 0.00654146634042263,\n",
       " -0.016942981630563736,\n",
       " -0.022612735629081726,\n",
       " 0.002688648412004113,\n",
       " -0.044328995048999786,\n",
       " 0.024361198768019676,\n",
       " -0.033095598220825195,\n",
       " -0.00516229635104537,\n",
       " -0.031173354014754295,\n",
       " -0.09072044491767883,\n",
       " -0.014549515210092068,\n",
       " 0.004583638161420822,\n",
       " 0.049915675073862076,\n",
       " -0.060631249099969864,\n",
       " 0.044668570160865784,\n",
       " 0.015613534487783909,\n",
       " 0.011485260911285877,\n",
       " -0.015320382080972195,\n",
       " -0.10558333992958069,\n",
       " 0.030622106045484543,\n",
       " 0.03029089793562889,\n",
       " -0.0012983001070097089,\n",
       " 0.0048263720236718655,\n",
       " 0.020714521408081055,\n",
       " 0.0020963167771697044,\n",
       " 0.023233413696289062,\n",
       " 0.013330990448594093,\n",
       " -0.006901805754750967,\n",
       " -0.030640268698334694,\n",
       " -0.009970290586352348,\n",
       " -0.005376889370381832,\n",
       " -0.04543115198612213,\n",
       " 0.031151121482253075,\n",
       " -0.07218685001134872,\n",
       " 0.011470994912087917,\n",
       " 0.007723487447947264,\n",
       " 0.009464144706726074,\n",
       " 0.030968351289629936,\n",
       " 0.03461812809109688,\n",
       " -0.023605952039361,\n",
       " 0.04239519685506821,\n",
       " -0.009796234779059887,\n",
       " -0.010984729044139385,\n",
       " -0.041256364434957504,\n",
       " 0.0576220266520977,\n",
       " 0.01242731511592865,\n",
       " -0.03846793249249458,\n",
       " -0.01635427214205265,\n",
       " -0.020342376083135605,\n",
       " -0.03353755548596382,\n",
       " -0.03208396956324577,\n",
       " 0.020605413243174553,\n",
       " 0.04728704318404198,\n",
       " -0.00017251218378078192,\n",
       " 0.013529548421502113,\n",
       " -0.021796785295009613,\n",
       " -0.03116178885102272,\n",
       " 0.0015166517114266753,\n",
       " -0.020448151975870132,\n",
       " 0.07500500231981277,\n",
       " -0.07423300296068192,\n",
       " -0.033331725746393204,\n",
       " 0.0015287840506061912,\n",
       " -0.021297316998243332,\n",
       " -0.019301699474453926,\n",
       " 0.005340074189007282,\n",
       " -0.024928422644734383,\n",
       " -0.009914587251842022,\n",
       " 0.026486389338970184,\n",
       " -0.0075083160772919655,\n",
       " 0.015461241826415062,\n",
       " 0.015985000878572464,\n",
       " 0.0025376295670866966,\n",
       " 0.06054900586605072,\n",
       " 0.0012255330802872777,\n",
       " 0.018753470852971077,\n",
       " -0.001261464785784483,\n",
       " -0.0871458500623703,\n",
       " 0.004170851316303015,\n",
       " -0.035168856382369995,\n",
       " 0.020551564171910286,\n",
       " 0.03872695937752724,\n",
       " 0.03827837109565735,\n",
       " -0.06573416292667389,\n",
       " 0.0028469113167375326,\n",
       " -0.00939683336764574,\n",
       " 0.008102120831608772,\n",
       " -0.023784292861819267,\n",
       " -0.019995056092739105,\n",
       " 0.013529909774661064,\n",
       " -0.019694607704877853,\n",
       " 0.006660193204879761,\n",
       " 0.023281823843717575,\n",
       " 0.04361885040998459,\n",
       " -0.04184115678071976,\n",
       " 0.046344876289367676,\n",
       " -0.013707499019801617,\n",
       " 0.012595443986356258,\n",
       " 0.029363976791501045,\n",
       " -0.04964214563369751,\n",
       " 0.018965356051921844,\n",
       " -0.005183707922697067,\n",
       " -0.037292856723070145,\n",
       " -0.00935811921954155,\n",
       " 0.04704953357577324,\n",
       " -0.028313392773270607,\n",
       " 0.0011401945957913995,\n",
       " 0.012877709232270718,\n",
       " -0.03394540026783943,\n",
       " -0.00014755342272110283,\n",
       " -0.027526546269655228,\n",
       " -0.005708929616957903,\n",
       " 0.04248857870697975,\n",
       " -0.013520954176783562,\n",
       " -0.03723737224936485,\n",
       " -0.05987759679555893,\n",
       " -0.012760690413415432,\n",
       " -0.006302112713456154,\n",
       " 0.01936655305325985,\n",
       " 0.08023498207330704,\n",
       " 0.041218291968107224,\n",
       " -0.015403984114527702,\n",
       " -0.020237643271684647,\n",
       " 0.042303089052438736,\n",
       " -0.02367306873202324,\n",
       " -0.0037292076740413904,\n",
       " -0.010774009861052036,\n",
       " 0.04946831986308098,\n",
       " 0.06024397909641266,\n",
       " 0.03570627048611641,\n",
       " 0.00035651918733492494,\n",
       " -0.023321477696299553,\n",
       " -0.03204093873500824,\n",
       " -0.03403674066066742,\n",
       " -0.02925444394350052,\n",
       " 0.04792552441358566,\n",
       " -0.0030014782678335905,\n",
       " 0.007101654540747404,\n",
       " 0.03622082620859146,\n",
       " 0.003443174995481968,\n",
       " 0.04017394036054611,\n",
       " 0.05929630249738693,\n",
       " 0.09713674336671829,\n",
       " 0.020986860617995262,\n",
       " 0.04675639420747757,\n",
       " -0.032708968967199326,\n",
       " 0.008592026308178902,\n",
       " -0.025158097967505455,\n",
       " 0.02170928567647934,\n",
       " 0.050850916653871536,\n",
       " 0.0008657873841002584,\n",
       " -0.02001488395035267,\n",
       " -0.014827447943389416,\n",
       " -0.00427923072129488,\n",
       " -0.0046573663130402565,\n",
       " 0.05016313120722771,\n",
       " -0.029058663174510002,\n",
       " -0.0001553441834403202,\n",
       " 0.015261068008840084,\n",
       " -0.012426198460161686,\n",
       " 0.07056024670600891,\n",
       " -0.016703730449080467,\n",
       " 0.014107407070696354,\n",
       " -0.008112186565995216,\n",
       " 0.021940339356660843,\n",
       " 0.011986629106104374,\n",
       " -0.030558401718735695,\n",
       " 0.02991092950105667,\n",
       " -0.018453067168593407,\n",
       " -0.049956634640693665,\n",
       " 0.0031484500505030155,\n",
       " 0.07819615304470062,\n",
       " -0.030340688303112984,\n",
       " 0.011669292114675045,\n",
       " -0.02844962291419506,\n",
       " -0.005301021505147219,\n",
       " 0.019725976511836052,\n",
       " -0.0013107506092637777,\n",
       " -0.02950393408536911,\n",
       " 0.016113009303808212,\n",
       " 0.031093748286366463,\n",
       " 0.019354280084371567,\n",
       " 0.0019303609151393175,\n",
       " 0.07418603450059891,\n",
       " -0.001999984961003065,\n",
       " 0.052811767905950546,\n",
       " 0.04897206276655197,\n",
       " -0.03095884807407856,\n",
       " 0.009967399761080742,\n",
       " -0.03918304666876793,\n",
       " -0.029494833201169968,\n",
       " -0.0562501884996891,\n",
       " 0.007986903190612793,\n",
       " 0.009587298147380352,\n",
       " -0.03746647760272026,\n",
       " -0.04238072782754898,\n",
       " -0.015826109796762466,\n",
       " 0.004899132531136274,\n",
       " 0.008634091354906559,\n",
       " 0.022248703986406326,\n",
       " 0.135790154337883,\n",
       " 0.03665019944310188,\n",
       " -0.07303182780742645,\n",
       " -0.040657222270965576,\n",
       " -0.01327226497232914,\n",
       " -0.023591866716742516,\n",
       " -0.005046928767114878,\n",
       " 0.00817981269210577,\n",
       " -0.025494659319519997,\n",
       " 0.04304274916648865,\n",
       " -0.02344108372926712,\n",
       " -0.04288093000650406,\n",
       " -0.04034613072872162,\n",
       " 0.02340269833803177,\n",
       " 0.006252244580537081,\n",
       " -0.015407130122184753,\n",
       " -0.018768509849905968,\n",
       " -0.006098630838096142,\n",
       " -0.0007721352740190923,\n",
       " -0.02843528240919113,\n",
       " -9.032389243657235e-06,\n",
       " -0.01801101118326187,\n",
       " -0.08686812967061996,\n",
       " -0.021214861422777176,\n",
       " 0.0601385235786438,\n",
       " -0.024417130276560783,\n",
       " 0.0077742403373122215,\n",
       " -0.0026882681995630264,\n",
       " -0.009716141037642956,\n",
       " 0.05279869958758354,\n",
       " 0.022433778271079063,\n",
       " -0.015540503896772861,\n",
       " -0.015795713290572166,\n",
       " 0.03060549683868885,\n",
       " 0.02913639135658741,\n",
       " 0.015983978286385536,\n",
       " 0.022245194762945175,\n",
       " -0.03349374979734421,\n",
       " 0.03915637731552124,\n",
       " -0.03374754264950752,\n",
       " 0.039671771228313446,\n",
       " 0.007292602676898241,\n",
       " 0.027375483885407448,\n",
       " -0.02754356525838375,\n",
       " -0.03960810974240303,\n",
       " 0.007665322627872229,\n",
       " 0.0035449594724923372,\n",
       " -0.06470964848995209,\n",
       " 0.0350225530564785,\n",
       " 0.08717574924230576,\n",
       " 0.024957502260804176,\n",
       " 0.02493472769856453,\n",
       " 0.012985545210540295,\n",
       " 0.009640214964747429,\n",
       " -0.012273498810827732,\n",
       " -0.036640096455812454,\n",
       " -0.026401933282613754,\n",
       " -0.027825722470879555,\n",
       " 0.011298525147140026,\n",
       " 0.026397641748189926,\n",
       " 0.01033236924558878,\n",
       " 0.03304633870720863,\n",
       " 0.05255758762359619,\n",
       " 0.049010373651981354,\n",
       " 0.05621793121099472,\n",
       " 0.036943595856428146,\n",
       " -0.03909117355942726,\n",
       " -0.03084222413599491,\n",
       " 0.02402479387819767,\n",
       " 0.017545364797115326,\n",
       " -0.044545408338308334,\n",
       " 0.007196065504103899,\n",
       " 0.022664150223135948,\n",
       " -0.00794889498502016,\n",
       " 0.0541103221476078,\n",
       " 0.08491469919681549,\n",
       " 0.028783459216356277,\n",
       " 0.060018036514520645,\n",
       " -0.013907807879149914,\n",
       " -0.1035693883895874,\n",
       " 0.07512791454792023,\n",
       " -0.07342329621315002,\n",
       " -0.016226138919591904,\n",
       " -0.03262084349989891,\n",
       " 0.03387404978275299,\n",
       " 0.08588141202926636,\n",
       " 0.006503901910036802,\n",
       " 0.0051481216214597225,\n",
       " -0.0023497308138757944,\n",
       " -0.005826239474117756,\n",
       " 0.1079372763633728,\n",
       " 0.03127725049853325,\n",
       " 0.06476076692342758,\n",
       " 0.026868704706430435,\n",
       " -0.10123135894536972,\n",
       " -0.019148394465446472,\n",
       " 0.028518155217170715,\n",
       " -0.018974587321281433,\n",
       " 0.025530552491545677,\n",
       " 0.020893897861242294,\n",
       " -0.020760679617524147,\n",
       " -0.04392610117793083,\n",
       " -0.035054031759500504,\n",
       " -0.016562970355153084,\n",
       " -0.07526754587888718,\n",
       " -0.03426341712474823,\n",
       " 0.00117526447866112,\n",
       " -0.023543154820799828,\n",
       " 0.05449233949184418,\n",
       " 0.048486992716789246,\n",
       " 0.00597821781411767,\n",
       " -0.030334223061800003,\n",
       " -0.013810797594487667,\n",
       " -0.005204188171774149,\n",
       " -0.015553092584013939,\n",
       " -0.003977770451456308,\n",
       " -0.04812087118625641,\n",
       " -0.008471420034766197,\n",
       " -0.005588662810623646,\n",
       " -0.006392513867467642,\n",
       " 0.02099757082760334,\n",
       " 0.028071772307157516,\n",
       " -0.00684006605297327]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.embed_query(\"What is the capital of Germany?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823647a",
   "metadata": {},
   "source": [
    "RAG PRACTICAL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc88860",
   "metadata": {},
   "source": [
    "1. DATA INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04beb07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753539065.160728 8997514 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from langchain_community) (0.3.69)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.10/site-packages (from langchain_community) (0.3.26)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from langchain_community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.13.2)\n",
      "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain_community) (3.11.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/alampata/Library/Python/3.10/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9b9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cef9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef0f349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.join(os.getcwd(), \"data\", \"sample.pdf\")\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9080dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov Thomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, calledLlama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for closed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements ofLlama 2-Chatin order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.\\narXiv:2307.09288v2  [cs.CL]  19 Jul 2023'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7e46f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Length 77\n"
     ]
    }
   ],
   "source": [
    "print('Document Length',len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f7cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked Docs 765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 70,\n",
       " 'page_label': '71'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print('Chunked Docs',len(texts))\n",
    "texts[700].page_content\n",
    "texts[700].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45cf9a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents(texts[0].page_content)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef18f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore=FAISS.from_documents(texts, embedding_model)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb054c",
   "metadata": {},
   "source": [
    "token->words\n",
    "\n",
    "chunk--> it is collection of words(token)[characters]\n",
    "\n",
    "1.in memory(faiss is in memory vector store,chroma)\n",
    "2. on disk storage(faiss you can persist over the disk,chroma)\n",
    "3. cloud storage(cloud variant of faiss is not available)(pinecone,weaviate,milvus,mongodbvectorsearch,astradb)\n",
    "\n",
    "This is a Retrieval proceesss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862f6cc",
   "metadata": {},
   "source": [
    "This is a Retrieval proceesss\n",
    "means from the vectordatabase we are going to fetch or retrive or rank the most appropriate k result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90279136",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6448aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='167b8e7d-5b7d-4aa9-bbb3-0cd748307cef', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='6f3bde3c-3c86-4b52-811f-c38b11b8abdb', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='676c09a0-a2bd-49a6-994f-918a318e50d8', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='d7bb8f84-4e38-4f2e-8c8e-80a6f1c812cf', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f026d218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75211c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[2].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905f553b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='167b8e7d-5b7d-4aa9-bbb3-0cd748307cef', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='6f3bde3c-3c86-4b52-811f-c38b11b8abdb', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='676c09a0-a2bd-49a6-994f-918a318e50d8', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='d7bb8f84-4e38-4f2e-8c8e-80a6f1c812cf', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.'),\n",
       " Document(id='712eec6f-38ad-4c25-b95d-761b3f6e7411', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 75, 'page_label': '76'}, page_content='small delta (-0.9) between the \"clean\" subset performance and the sampling mean. No other dataset (for any\\nchoice ofL) appears to have benefitted from dataset contamination, and we omit results from these datasets\\nfor conciseness.\\n76'),\n",
       " Document(id='7b64e163-4aba-467e-b22e-84e507753a88', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 48, 'page_label': '49'}, page_content='Human-Eval and MBPP respectively. For pass@100 and pass@80 scores, we use a temperature of 0.8 and\\ntop-p=0.95. For pass@1 scores, we use a temperature of 0.1 and top-p=0.95.\\n49'),\n",
       " Document(id='d7f7b9b9-fafb-48bd-9592-3727e7669817', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 1, 'page_label': '2'}, page_content='Contents\\n1 Introduction 3\\n2 Pretraining 5\\n2.1 Pretraining Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Training Details . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.3 Llama 2Pretrained Model Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n3 Fine-tuning 8\\n3.1 Supervised Fine-Tuning (SFT) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9'),\n",
       " Document(id='67f08090-91da-49f1-952a-ec0381b2b140', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2'),\n",
       " Document(id='773e506f-d8e8-4cd0-a9d6-719eac5b90bc', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 72, 'page_label': '73'}, page_content='Llama 2\\n7B 0.15 0.30 0.12 0.35 0.25 0.43 0.18 0.38 0.16 0.12 0.29 -0.1313B 0.14 0.35 0.23 0.29 0.23 0.57 0.20 0.52 0.22 0.12 0.29 -0.1734B 0.12 0.16 0.18 0.36 0.35 0.52 0.10 0.54 0.28 0.11 0.30 -0.1970B 0.16 0.21 0.17 0.35 0.30 0.60 0.18 0.67 0.26 0.12 0.30 -0.10\\nFine-tuned\\nChatGPT 0.15 0.22 0.05 0.24 0.31 0.35 0.09 0.42 0.19 0.09 0.23 0.06MPT-instruct 7B 0.13 0.29 0.12 0.34 0.35 0.53 0.28 0.56 0.27 0.02 0.32 -0.12Falcon-instruct 7B 0.11 0.21 0.21 0.28 0.34 0.23 0.31 0.45 0.23 0.22 0.29 -0.27'),\n",
       " Document(id='c9b1bfad-83c4-48e5-b954-4dafa132005a', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 2, 'page_label': '3'}, page_content='be on par with some of the closed-source models, at least on the human evaluations we performed (see\\nFigures 1 and 3). We have taken measures to increase the safety of these models, using safety-specific data\\nannotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally,\\nthis paper contributes a thorough description of our fine-tuning methodology and approach to improving')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"llama2 finetuning benchmark experiments.\",k=10)\n",
    "relevant_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4cba514",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5af9a0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='167b8e7d-5b7d-4aa9-bbb3-0cd748307cef', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 7, 'page_label': '8'}, page_content='13B 18.9 66.1 52.6 62.3 10.9 46.9 37.0 33.9\\n33B 26.0 70.0 58.4 67.6 21.4 57.8 39.8 41.7\\n65B 30.7 70.7 60.5 68.6 30.8 63.4 43.5 47.6\\nLlama 2\\n7B 16.8 63.9 48.9 61.3 14.6 45.3 32.6 29.3\\n13B 24.5 66.9 55.4 65.8 28.7 54.8 39.4 39.1\\n34B 27.8 69.9 58.7 68.0 24.2 62.6 44.1 43.4\\n70B 37.5 71.9 63.6 69.4 35.2 68.9 51.2 54.2\\nTable 3: Overall performance on grouped academic benchmarks compared to open-source base models.'),\n",
       " Document(id='6f3bde3c-3c86-4b52-811f-c38b11b8abdb', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned'),\n",
       " Document(id='676c09a0-a2bd-49a6-994f-918a318e50d8', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 70, 'page_label': '71'}, page_content='65B 14.27 31.59 21.90 14.89 23.51 22.27 17.16 18.91 28.40 19.32 28.71 22.00 20.03\\nLlama 2\\n7B 16.53 31.15 22.63 15.74 26.87 19.95 15.79 19.55 25.03 18.92 21.53 22.34 20.20\\n13B 21.29 37.25 22.81 17.77 32.65 24.13 21.05 20.19 35.40 27.69 26.99 28.26 23.84\\n34B 16.76 29.63 23.36 14.38 27.43 19.49 18.54 17.31 26.38 18.73 22.78 21.66 19.04\\n70B 21.29 32.90 25.91 16.92 30.60 21.35 16.93 21.47 30.42 20.12 31.05 28.43 22.35\\nFine-tuned\\nChatGPT 0.23 0.22 0.18 0 0.19 0 0.46 0 0.13 0 0.47 0 0.66'),\n",
       " Document(id='d7bb8f84-4e38-4f2e-8c8e-80a6f1c812cf', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': '/Users/alampata/Desktop/LLMOPS/DOCUMENT-RAG-PORTAL/notebook/data/sample.pdf', 'total_pages': 77, 'page': 6, 'page_label': '7'}, page_content='models internally. For these models, we always pick the best score between our evaluation framework and\\nany publicly reported results.\\nIn Table 3, we summarize the overall performance across a suite of popular benchmarks. Note that safety\\nbenchmarks are shared in Section 4.1. The benchmarks are grouped into the categories listed below. The\\nresults for all the individual benchmarks are available in Section A.2.2.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "retriever.invoke(\"llama2 finetuning benchmark experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a4a6a",
   "metadata": {},
   "source": [
    "Question: user question\n",
    "Context: based on the question retrieving the info from the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6e76459",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "        Answer the question based on the context provided below. \n",
    "        If the context does not contain sufficient information, respond with: \n",
    "        \"I do not have enough information about this.\"\n",
    "\n",
    "        Context: {context}\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Answer:\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c487d05a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d87a643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n        Answer the question based on the context provided below. \\n        If the context does not contain sufficient information, respond with: \\n        \"I do not have enough information about this.\"\\n\\n        Context: {context}\\n\\n        Question: {question}\\n\\n        Answer:')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db23641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84722030",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "691859f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f98c99b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7fad4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, I need to figure out how to answer the question about the Llama 2 fine-tuning benchmark experiments based on the provided context. Let me start by reading through the context carefully to see what information is available.\\n\\nLooking at the context, I see several tables with numbers and some text. The first table mentions \"Overall performance on grouped academic benchmarks\" and includes models like 13B, 33B, 65B, and Llama 2 with different sizes (7B, 13B, 34B, 70B). The numbers seem to represent some sort of performance metrics across various benchmarks.\\n\\nThen there\\'s a second table labeled \"Fine-tuned\" with models like ChatGPT and Llama 2. The numbers here are much smaller, mostly below 1, which might indicate some kind of score or metric, perhaps related to fine-tuning. The text below mentions that for these models, the best score is picked between their evaluation framework and publicly reported results.\\n\\nThe question is asking about the Llama 2 fine-tuning benchmark experiments. From the context, the second table specifically mentions \"Fine-tuned\" and includes Llama 2 with different sizes (7B, 13B, 34B, 70B) and a series of numbers. The text also says that safety benchmarks are in Section 4.1, but that\\'s not relevant here.\\n\\nSo, the answer should focus on the information in the second table. It shows that Llama 2 models of various sizes have been fine-tuned, and their performance is summarized with specific metrics. The numbers likely represent some form of benchmark scores, possibly showing improvement or specific capabilities after fine-tuning.\\n\\nI should explain that the context includes a table summarizing the performance of fine-tuned Llama 2 models across different benchmarks, with each model size (7B, 13B, 34B, 70B) having its own set of scores. The exact nature of these scores isn\\'t explicitly stated, but they\\'re part of the overall evaluation framework mentioned in the text.\\n\\nI need to structure the answer to clearly state that the context includes a table detailing the fine-tuning experiments for Llama 2 models, mentioning the different sizes and the metrics provided. However, without specific details on what the metrics represent, I can\\'t go into deeper explanations, so I\\'ll stick to what\\'s provided.\\n\\nSo, putting it all together, the answer will mention the table, the models, and the metrics, indicating that the context provides a summary of their performance after fine-tuning.\\n</think>\\n\\nThe context includes a table summarizing the performance of fine-tuned Llama 2 models across various benchmarks. The table lists different model sizes: 7B, 13B, 34B, and 70B, each accompanied by a series of metrics. These metrics likely represent benchmark scores, indicating the models\\' performance after fine-tuning. The exact nature of these scores isn\\'t detailed, but they are part of an evaluation framework comparing internal results with publicly reported data. This table provides an overview of how each Llama 2 model size performs in fine-tuned experiments.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about the llama2 finetuning benchmark experiments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd13d8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, so I need to figure out what the question is asking. The user wants me to explain about \"Popular Aggregated Benchmarks\" based on the provided context. Let me read through the context again to find relevant information.\\n\\nLooking at the context, I see a mention of \"Popular Aggregated Benchmarks\" in Table 3. It says they report overall results for MMLU, Big Bench Hard, and AGI Eval. Each of these has specific details: MMLU uses 5 shots, BBH uses 3 shots, and AGI Eval uses 3-5 shots, but only on English tasks, averaging the results.\\n\\nI should structure the answer by listing each benchmark with their respective details. I need to make sure I include the authors and years in parentheses for each benchmark. Also, note that for AGI Eval, they only used English tasks. \\n\\nI should present this information clearly, maybe in bullet points for readability. But since the user mentioned not to use markdown, I\\'ll just format it with line breaks and dashes.\\n\\nWait, in the context, it says \"MMLU (5 shot) (Hendrycks et al., 2020)\", so I should include the number of shots and the citation. Similarly for the others. \\n\\nI should also explain that these are the specific benchmarks they evaluated on, giving a brief description of each if possible, but the context doesn\\'t provide much beyond the names and parameters. So I\\'ll stick to what\\'s given.\\n\\nI think that\\'s all the relevant information. Now, I\\'ll structure the answer accordingly.\\n</think>\\n\\nThe Popular Aggregated Benchmarks mentioned in the context include:\\n\\n- **MMLU (5 shot)** by Hendrycks et al. (2020)\\n- **Big Bench Hard (BBH) (3 shot)** by Suzgun et al. (2022)\\n- **AGI Eval (3–5 shot)** by Zhong et al. (2023), which focuses only on English tasks and reports an average of the results.\\n\\nThese benchmarks are used to evaluate overall performance, with specific shot counts for each.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"tell  me about Popular Aggregated Benchmarks.?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
